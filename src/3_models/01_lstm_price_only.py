"""
01_lstm_price_only.py

åŠŸèƒ½ï¼š
- ä» merged_features.csv è¯»å–æ•°æ®
- åªä½¿ç”¨â€œä»·æ ¼ç›¸å…³ç‰¹å¾â€ä½œä¸ºè¾“å…¥ Xï¼ˆä¸å«æƒ…ç»ªï¼‰
- åšæ—¶é—´åºåˆ—åˆ‡ç‰‡ï¼ˆLSTM è¾“å…¥ï¼šæ ·æœ¬æ•° Ã— lookback Ã— ç‰¹å¾æ•°ï¼‰
- åˆ’åˆ† train / val / test
- è®­ç»ƒ LSTM æ¨¡å‹ï¼Œè¯„ä¼° RMSE
- ä¿å­˜ï¼š
    - æ¨¡å‹ï¼šoutputs/lstm_price_only.h5
    - æŒ‡æ ‡ï¼šoutputs/metrics.csvï¼ˆè¿½åŠ ä¸€è¡Œï¼‰
"""

from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers


# ====== åŸºç¡€å·¥å…· ======

def get_project_root() -> Path:
    return Path(__file__).resolve().parents[2]


def create_sequences(X, y, lookback: int):
    """
    æŠŠæŒ‰æ—¶é—´æ’åºå¥½çš„ 2D ç‰¹å¾ + 1D ç›®æ ‡ï¼Œåˆ‡æˆ LSTM éœ€è¦çš„ 3D åºåˆ—ã€‚
    X: (N, num_features)
    y: (N,)
    return:
        X_seq: (N-lookback, lookback, num_features)
        y_seq: (N-lookback,)
    """
    Xs, ys = [], []
    for i in range(len(X) - lookback):
        Xs.append(X[i : i + lookback])
        ys.append(y[i + lookback])
    return np.array(Xs), np.array(ys)


# ====== ä¸»æµç¨‹ ======

def main():
    project_root = get_project_root()
    data_path = project_root / "data" / "features" / "merged_features.csv"
    outputs_dir = project_root / "outputs"
    outputs_dir.mkdir(parents=True, exist_ok=True)
    model_path = outputs_dir / "lstm_price_only.h5"
    metrics_path = outputs_dir / "metrics.csv"

    print(f"ğŸ“¥ Reading merged features from {data_path}")
    df = pd.read_csv(data_path, parse_dates=["date"])

    # 1. é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆåªç”¨ä»·æ ¼ / æŠ€æœ¯ç›¸å…³ï¼Œä¸å« sentimentï¼‰
    # ä½ å¯ä»¥æ ¹æ®è‡ªå·±åœ¨ stock_features é‡Œç”Ÿæˆçš„åˆ—åè°ƒæ•´ä¸€ä¸‹
    price_feature_cols = [
        "open",
        "high",
        "low",
        "close",
        "adj_close",
        "volume",
        "return_1d",
        "return_lag_1",
        "return_lag_3",
        "return_lag_7",
        "roll_mean_5",
        "roll_std_5",
        "log_price",
    ]

    # ç¡®ä¿è¿™äº›åˆ—éƒ½åœ¨ df é‡Œ
    price_feature_cols = [c for c in price_feature_cols if c in df.columns]
    print("âœ… ä½¿ç”¨çš„ Price ç‰¹å¾åˆ—ï¼š", price_feature_cols)

    # ç›®æ ‡å˜é‡
    target_col = "target_return_1d"

    # 2. æŒ‰æ—¥æœŸæ’åºï¼ˆå·²ç»å«æœ‰å¤šä¸ª tickerï¼Œä¸€èµ·æŒ‰æ—¶é—´æ’ï¼‰
    df = df.sort_values(["date", "ticker"]).reset_index(drop=True)

    # 3. å–å‡ºç‰¹å¾å’Œç›®æ ‡
    X_all = df[price_feature_cols].values.astype(float)
    y_all = df[target_col].values.astype(float)

    # 4. Train / Val / Test æŒ‰æ—¶é—´æ¯”ä¾‹åˆ‡åˆ†ï¼ˆä¾‹å¦‚ 70% / 15% / 15%ï¼‰
    n = len(df)
    train_end = int(n * 0.7)
    val_end = int(n * 0.85)

    X_train_raw, y_train_raw = X_all[:train_end], y_all[:train_end]
    X_val_raw, y_val_raw = X_all[train_end:val_end], y_all[train_end:val_end]
    X_test_raw, y_test_raw = X_all[val_end:], y_all[val_end:]

    print(f"ğŸ“Š æ ·æœ¬æ•°ï¼štrain={len(X_train_raw)}, val={len(X_val_raw)}, test={len(X_test_raw)}")

    # 5. å¯¹ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆåªåœ¨ train ä¸Š fitï¼‰
    scaler = StandardScaler()
    scaler.fit(X_train_raw)

    X_train_scaled = scaler.transform(X_train_raw)
    X_val_scaled = scaler.transform(X_val_raw)
    X_test_scaled = scaler.transform(X_test_raw)

    # 6. æ„é€ æ—¶é—´åºåˆ—åˆ‡ç‰‡
    lookback = 20  # ç”¨è¿‡å» 20 å¤©çš„æ•°æ®é¢„æµ‹ä¸‹ä¸€å¤©

    X_train_seq, y_train = create_sequences(X_train_scaled, y_train_raw, lookback)
    X_val_seq, y_val = create_sequences(X_val_scaled, y_val_raw, lookback)
    X_test_seq, y_test = create_sequences(X_test_scaled, y_test_raw, lookback)

    print("ğŸ“ LSTM è¾“å…¥ç»´åº¦ï¼š", X_train_seq.shape)

    # 7. å®šä¹‰ LSTM æ¨¡å‹ï¼ˆä»·æ ¼-onlyï¼‰
    num_features = X_train_seq.shape[-1]

    model = keras.Sequential(
        [
            layers.Input(shape=(lookback, num_features)),
            layers.LSTM(64, return_sequences=False),
            layers.Dense(32, activation="relu"),
            layers.Dense(1, activation="linear"),  # å›å½’
        ]
    )

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-3),
        loss="mse",
        metrics=["mae"],
    )

    model.summary()

    # 8. è®­ç»ƒ
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor="val_loss", patience=5, restore_best_weights=True
        )
    ]

    history = model.fit(
        X_train_seq,
        y_train,
        epochs=50,
        batch_size=64,
        validation_data=(X_val_seq, y_val),
        callbacks=callbacks,
        verbose=1,
    )

    # 9. åœ¨ test é›†ä¸Šè¯„ä¼° RMSE / MAE
    y_pred = model.predict(X_test_seq).ravel()
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)

    print(f"âœ… Test RMSE = {rmse:.6f}, MAE = {mae:.6f}")

    # 10. ä¿å­˜æ¨¡å‹
    model.save(model_path)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")

    # 11. è®°å½• metrics.csvï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
    row = {
        "model_name": "lstm_price_only",
        "use_sentiment": 0,
        "rmse": rmse,
        "mae": mae,
    }

    if metrics_path.exists():
        metrics_df = pd.read_csv(metrics_path)
        metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)
    else:
        metrics_df = pd.DataFrame([row])

    metrics_df.to_csv(metrics_path, index=False)
    print(f"ğŸ“ˆ æŒ‡æ ‡å·²å†™å…¥ {metrics_path}")
    print(metrics_df.tail())


if __name__ == "__main__":
    main()
